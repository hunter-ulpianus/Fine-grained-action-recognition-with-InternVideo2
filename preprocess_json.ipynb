{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "final_list = []\n",
    "# 加载 action_candidates.json 文件内容\n",
    "with open(\"/media/sdc/datasets/ssv2/action_candidates.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    action_candidates = json.load(f)\n",
    "\n",
    "# 加载 validation.json 文件内容\n",
    "with open(\"/media/sdc/datasets/ssv2/annotations/validation.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    validation_data = json.load(f)\n",
    "\n",
    "# 更新 validation.json 数据，添加 \"option\" 键\n",
    "for item in validation_data:\n",
    "    item[\"option\"] = action_candidates\n",
    "    final_list.append(item)\n",
    "\n",
    "# 将更新后的数据写回到 validation.json 文件\n",
    "with open(\"/media/sdc/datasets/ssv2/validation_update.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(final_list, f, ensure_ascii=False)\n",
    "\n",
    "print(\"已成功更新 validation.json 文件，并保存为 validation_updated.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "val_label_path = \"/media/sdc/datasets/ssv2/train_frame_label.json\"\n",
    "val_answer_option_path = \"/media/sdc/datasets/ssv2/train_with_caption.json\"\n",
    "actions_path = \"/media/sdc/datasets/ssv2/annotations/labels.json\"\n",
    "options_path = \"/media/sdc/datasets/ssv2/action_candidates.json\"\n",
    "\n",
    "with open(options_path, 'r') as fp:\n",
    "    options = json.load(fp)\n",
    "\n",
    "val_list = []\n",
    "\n",
    "with open(val_label_path, 'r') as fp:\n",
    "    ori_val_file = json.load(fp)\n",
    "    with open(val_answer_option_path, 'r') as f:\n",
    "        ori_answer_file = json.load(f)\n",
    "        for val_label_item in ori_val_file:\n",
    "            val_item = {}\n",
    "            val_item[\"id\"] = val_label_item[\"id\"]\n",
    "            val_item[\"image\"] = val_label_item[\"image\"]\n",
    "            with open(actions_path, 'r') as ac:\n",
    "                action = json.load(ac)\n",
    "\n",
    "                caption = next(item[\"caption\"] for item in ori_answer_file if item[\"video\"] == val_label_item[\"id\"])\n",
    "                val_item[\"caption\"] = caption\n",
    "                val_item[\"answer\"] = action[caption]\n",
    "                val_item[\"options\"] = options\n",
    "                val_list.append(val_item)\n",
    "\n",
    "json.dump(val_list, open('/media/sdc/datasets/ssv2/train_frames_label_options.json', 'w'))\n",
    "print(f\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/media/sdc/fe/ckpt_L14_ret/ckpt_best.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/media/sdc/fe/ckpt_L14_ret/ckpt_best.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(model[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m~/anaconda3/envs/viclip/lib/python3.8/site-packages/torch/serialization.py:791\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    789\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    793\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    796\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/envs/viclip/lib/python3.8/site-packages/torch/serialization.py:271\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 271\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    273\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/envs/viclip/lib/python3.8/site-packages/torch/serialization.py:252\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 252\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/media/sdc/fe/ckpt_L14_ret/ckpt_best.pth'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.load(\"/media/sdc/fe/ckpt_L14_ret/ckpt_best.pth\")\n",
    "\n",
    "print(model[\"model\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding cls_token from vision_ckpt\n",
      "Adding pos_embed from vision_ckpt\n",
      "Adding patch_embed.proj.weight from vision_ckpt\n",
      "Adding patch_embed.proj.bias from vision_ckpt\n",
      "Adding blocks.0.norm1.weight from vision_ckpt\n",
      "Adding blocks.0.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.0.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.0.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.0.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.0.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.0.ls1.gamma from vision_ckpt\n",
      "Adding blocks.0.norm2.weight from vision_ckpt\n",
      "Adding blocks.0.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.0.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.0.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.0.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.0.ls2.gamma from vision_ckpt\n",
      "Adding blocks.1.norm1.weight from vision_ckpt\n",
      "Adding blocks.1.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.1.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.1.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.1.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.1.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.1.ls1.gamma from vision_ckpt\n",
      "Adding blocks.1.norm2.weight from vision_ckpt\n",
      "Adding blocks.1.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.1.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.1.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.1.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.1.ls2.gamma from vision_ckpt\n",
      "Adding blocks.2.norm1.weight from vision_ckpt\n",
      "Adding blocks.2.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.2.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.2.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.2.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.2.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.2.ls1.gamma from vision_ckpt\n",
      "Adding blocks.2.norm2.weight from vision_ckpt\n",
      "Adding blocks.2.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.2.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.2.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.2.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.2.ls2.gamma from vision_ckpt\n",
      "Adding blocks.3.norm1.weight from vision_ckpt\n",
      "Adding blocks.3.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.3.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.3.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.3.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.3.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.3.ls1.gamma from vision_ckpt\n",
      "Adding blocks.3.norm2.weight from vision_ckpt\n",
      "Adding blocks.3.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.3.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.3.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.3.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.3.ls2.gamma from vision_ckpt\n",
      "Adding blocks.4.norm1.weight from vision_ckpt\n",
      "Adding blocks.4.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.4.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.4.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.4.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.4.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.4.ls1.gamma from vision_ckpt\n",
      "Adding blocks.4.norm2.weight from vision_ckpt\n",
      "Adding blocks.4.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.4.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.4.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.4.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.4.ls2.gamma from vision_ckpt\n",
      "Adding blocks.5.norm1.weight from vision_ckpt\n",
      "Adding blocks.5.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.5.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.5.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.5.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.5.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.5.ls1.gamma from vision_ckpt\n",
      "Adding blocks.5.norm2.weight from vision_ckpt\n",
      "Adding blocks.5.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.5.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.5.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.5.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.5.ls2.gamma from vision_ckpt\n",
      "Adding blocks.6.norm1.weight from vision_ckpt\n",
      "Adding blocks.6.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.6.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.6.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.6.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.6.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.6.ls1.gamma from vision_ckpt\n",
      "Adding blocks.6.norm2.weight from vision_ckpt\n",
      "Adding blocks.6.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.6.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.6.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.6.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.6.ls2.gamma from vision_ckpt\n",
      "Adding blocks.7.norm1.weight from vision_ckpt\n",
      "Adding blocks.7.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.7.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.7.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.7.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.7.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.7.ls1.gamma from vision_ckpt\n",
      "Adding blocks.7.norm2.weight from vision_ckpt\n",
      "Adding blocks.7.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.7.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.7.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.7.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.7.ls2.gamma from vision_ckpt\n",
      "Adding blocks.8.norm1.weight from vision_ckpt\n",
      "Adding blocks.8.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.8.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.8.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.8.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.8.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.8.ls1.gamma from vision_ckpt\n",
      "Adding blocks.8.norm2.weight from vision_ckpt\n",
      "Adding blocks.8.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.8.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.8.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.8.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.8.ls2.gamma from vision_ckpt\n",
      "Adding blocks.9.norm1.weight from vision_ckpt\n",
      "Adding blocks.9.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.9.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.9.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.9.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.9.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.9.ls1.gamma from vision_ckpt\n",
      "Adding blocks.9.norm2.weight from vision_ckpt\n",
      "Adding blocks.9.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.9.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.9.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.9.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.9.ls2.gamma from vision_ckpt\n",
      "Adding blocks.10.norm1.weight from vision_ckpt\n",
      "Adding blocks.10.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.10.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.10.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.10.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.10.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.10.ls1.gamma from vision_ckpt\n",
      "Adding blocks.10.norm2.weight from vision_ckpt\n",
      "Adding blocks.10.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.10.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.10.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.10.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.10.ls2.gamma from vision_ckpt\n",
      "Adding blocks.11.norm1.weight from vision_ckpt\n",
      "Adding blocks.11.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.11.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.11.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.11.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.11.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.11.ls1.gamma from vision_ckpt\n",
      "Adding blocks.11.norm2.weight from vision_ckpt\n",
      "Adding blocks.11.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.11.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.11.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.11.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.11.ls2.gamma from vision_ckpt\n",
      "Adding blocks.12.norm1.weight from vision_ckpt\n",
      "Adding blocks.12.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.12.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.12.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.12.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.12.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.12.ls1.gamma from vision_ckpt\n",
      "Adding blocks.12.norm2.weight from vision_ckpt\n",
      "Adding blocks.12.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.12.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.12.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.12.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.12.ls2.gamma from vision_ckpt\n",
      "Adding blocks.13.norm1.weight from vision_ckpt\n",
      "Adding blocks.13.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.13.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.13.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.13.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.13.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.13.ls1.gamma from vision_ckpt\n",
      "Adding blocks.13.norm2.weight from vision_ckpt\n",
      "Adding blocks.13.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.13.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.13.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.13.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.13.ls2.gamma from vision_ckpt\n",
      "Adding blocks.14.norm1.weight from vision_ckpt\n",
      "Adding blocks.14.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.14.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.14.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.14.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.14.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.14.ls1.gamma from vision_ckpt\n",
      "Adding blocks.14.norm2.weight from vision_ckpt\n",
      "Adding blocks.14.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.14.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.14.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.14.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.14.ls2.gamma from vision_ckpt\n",
      "Adding blocks.15.norm1.weight from vision_ckpt\n",
      "Adding blocks.15.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.15.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.15.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.15.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.15.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.15.ls1.gamma from vision_ckpt\n",
      "Adding blocks.15.norm2.weight from vision_ckpt\n",
      "Adding blocks.15.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.15.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.15.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.15.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.15.ls2.gamma from vision_ckpt\n",
      "Adding blocks.16.norm1.weight from vision_ckpt\n",
      "Adding blocks.16.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.16.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.16.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.16.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.16.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.16.ls1.gamma from vision_ckpt\n",
      "Adding blocks.16.norm2.weight from vision_ckpt\n",
      "Adding blocks.16.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.16.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.16.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.16.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.16.ls2.gamma from vision_ckpt\n",
      "Adding blocks.17.norm1.weight from vision_ckpt\n",
      "Adding blocks.17.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.17.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.17.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.17.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.17.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.17.ls1.gamma from vision_ckpt\n",
      "Adding blocks.17.norm2.weight from vision_ckpt\n",
      "Adding blocks.17.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.17.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.17.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.17.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.17.ls2.gamma from vision_ckpt\n",
      "Adding blocks.18.norm1.weight from vision_ckpt\n",
      "Adding blocks.18.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.18.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.18.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.18.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.18.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.18.ls1.gamma from vision_ckpt\n",
      "Adding blocks.18.norm2.weight from vision_ckpt\n",
      "Adding blocks.18.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.18.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.18.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.18.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.18.ls2.gamma from vision_ckpt\n",
      "Adding blocks.19.norm1.weight from vision_ckpt\n",
      "Adding blocks.19.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.19.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.19.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.19.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.19.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.19.ls1.gamma from vision_ckpt\n",
      "Adding blocks.19.norm2.weight from vision_ckpt\n",
      "Adding blocks.19.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.19.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.19.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.19.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.19.ls2.gamma from vision_ckpt\n",
      "Adding blocks.20.norm1.weight from vision_ckpt\n",
      "Adding blocks.20.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.20.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.20.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.20.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.20.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.20.ls1.gamma from vision_ckpt\n",
      "Adding blocks.20.norm2.weight from vision_ckpt\n",
      "Adding blocks.20.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.20.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.20.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.20.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.20.ls2.gamma from vision_ckpt\n",
      "Adding blocks.21.norm1.weight from vision_ckpt\n",
      "Adding blocks.21.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.21.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.21.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.21.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.21.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.21.ls1.gamma from vision_ckpt\n",
      "Adding blocks.21.norm2.weight from vision_ckpt\n",
      "Adding blocks.21.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.21.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.21.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.21.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.21.ls2.gamma from vision_ckpt\n",
      "Adding blocks.22.norm1.weight from vision_ckpt\n",
      "Adding blocks.22.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.22.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.22.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.22.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.22.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.22.ls1.gamma from vision_ckpt\n",
      "Adding blocks.22.norm2.weight from vision_ckpt\n",
      "Adding blocks.22.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.22.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.22.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.22.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.22.ls2.gamma from vision_ckpt\n",
      "Adding blocks.23.norm1.weight from vision_ckpt\n",
      "Adding blocks.23.attn.qkv.weight from vision_ckpt\n",
      "Adding blocks.23.attn.proj.weight from vision_ckpt\n",
      "Adding blocks.23.attn.proj.bias from vision_ckpt\n",
      "Adding blocks.23.attn.q_norm.weight from vision_ckpt\n",
      "Adding blocks.23.attn.k_norm.weight from vision_ckpt\n",
      "Adding blocks.23.ls1.gamma from vision_ckpt\n",
      "Adding blocks.23.norm2.weight from vision_ckpt\n",
      "Adding blocks.23.mlp.fc1.weight from vision_ckpt\n",
      "Adding blocks.23.mlp.fc1.bias from vision_ckpt\n",
      "Adding blocks.23.mlp.fc2.weight from vision_ckpt\n",
      "Adding blocks.23.mlp.fc2.bias from vision_ckpt\n",
      "Adding blocks.23.ls2.gamma from vision_ckpt\n",
      "Adding clip_projector.norm1_q.weight from vision_ckpt\n",
      "Adding clip_projector.norm1_q.bias from vision_ckpt\n",
      "Adding clip_projector.norm1_k.weight from vision_ckpt\n",
      "Adding clip_projector.norm1_k.bias from vision_ckpt\n",
      "Adding clip_projector.norm1_v.weight from vision_ckpt\n",
      "Adding clip_projector.norm1_v.bias from vision_ckpt\n",
      "Adding clip_projector.cross_attn.q_bias from vision_ckpt\n",
      "Adding clip_projector.cross_attn.k_bias from vision_ckpt\n",
      "Adding clip_projector.cross_attn.v_bias from vision_ckpt\n",
      "Adding clip_projector.cross_attn.q.weight from vision_ckpt\n",
      "Adding clip_projector.cross_attn.k.weight from vision_ckpt\n",
      "Adding clip_projector.cross_attn.v.weight from vision_ckpt\n",
      "Adding clip_projector.cross_attn.proj.weight from vision_ckpt\n",
      "Adding clip_projector.cross_attn.proj.bias from vision_ckpt\n",
      "Adding fc_norm.weight from vision_ckpt\n",
      "Adding fc_norm.bias from vision_ckpt\n",
      "Adding head.weight from vision_ckpt\n",
      "Adding head.bias from vision_ckpt\n",
      "Adding logit_scale from vision_ckpt\n",
      "Adding image_encoder.model.cls_token from vision_ckpt\n",
      "Adding image_encoder.model.patch_emb.0.block.conv.weight from vision_ckpt\n",
      "Adding image_encoder.model.patch_emb.0.block.norm.weight from vision_ckpt\n",
      "Adding image_encoder.model.patch_emb.0.block.norm.bias from vision_ckpt\n",
      "Adding image_encoder.model.patch_emb.0.block.norm.running_mean from vision_ckpt\n",
      "Adding image_encoder.model.patch_emb.0.block.norm.running_var from vision_ckpt\n",
      "Adding image_encoder.model.patch_emb.0.block.norm.num_batches_tracked from vision_ckpt\n",
      "Adding image_encoder.model.patch_emb.1.block.conv.weight from vision_ckpt\n",
      "Adding image_encoder.model.patch_emb.1.block.norm.weight from vision_ckpt\n",
      "Adding image_encoder.model.patch_emb.1.block.norm.bias from vision_ckpt\n",
      "Adding image_encoder.model.patch_emb.1.block.norm.running_mean from vision_ckpt\n",
      "Adding image_encoder.model.patch_emb.1.block.norm.running_var from vision_ckpt\n",
      "Adding image_encoder.model.patch_emb.1.block.norm.num_batches_tracked from vision_ckpt\n",
      "Adding image_encoder.model.patch_emb.2.block.conv.weight from vision_ckpt\n",
      "Adding image_encoder.model.patch_emb.2.block.conv.bias from vision_ckpt\n",
      "Adding image_encoder.model.post_transformer_norm.weight from vision_ckpt\n",
      "Adding image_encoder.model.post_transformer_norm.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.0.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.0.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.0.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.0.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.0.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.0.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.0.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.0.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.0.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.0.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.0.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.0.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.1.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.1.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.1.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.1.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.1.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.1.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.1.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.1.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.1.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.1.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.1.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.1.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.2.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.2.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.2.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.2.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.2.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.2.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.2.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.2.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.2.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.2.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.2.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.2.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.3.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.3.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.3.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.3.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.3.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.3.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.3.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.3.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.3.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.3.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.3.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.3.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.4.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.4.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.4.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.4.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.4.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.4.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.4.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.4.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.4.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.4.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.4.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.4.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.5.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.5.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.5.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.5.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.5.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.5.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.5.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.5.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.5.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.5.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.5.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.5.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.6.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.6.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.6.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.6.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.6.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.6.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.6.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.6.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.6.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.6.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.6.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.6.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.7.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.7.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.7.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.7.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.7.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.7.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.7.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.7.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.7.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.7.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.7.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.7.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.8.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.8.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.8.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.8.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.8.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.8.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.8.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.8.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.8.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.8.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.8.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.8.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.9.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.9.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.9.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.9.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.9.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.9.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.9.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.9.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.9.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.9.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.9.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.9.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.10.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.10.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.10.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.10.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.10.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.10.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.10.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.10.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.10.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.10.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.10.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.10.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.11.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.11.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.11.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.11.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.11.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.11.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.11.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.11.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.11.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.11.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding image_encoder.model.transformer.11.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding image_encoder.model.transformer.11.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding image_encoder.model.classifier.proj from vision_ckpt\n",
      "Adding image_encoder.model.pos_embed.pos_embed.pos_embed from vision_ckpt\n",
      "Adding text_encoder.projection_layer from vision_ckpt\n",
      "Adding text_encoder.embedding_layer.weight from vision_ckpt\n",
      "Adding text_encoder.positional_embedding.pos_embed.pos_embed from vision_ckpt\n",
      "Adding text_encoder.transformer.0.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.0.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.0.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.0.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.0.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.0.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.0.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.0.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.0.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.0.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.0.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.0.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.1.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.1.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.1.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.1.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.1.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.1.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.1.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.1.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.1.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.1.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.1.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.1.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.2.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.2.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.2.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.2.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.2.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.2.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.2.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.2.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.2.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.2.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.2.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.2.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.3.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.3.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.3.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.3.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.3.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.3.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.3.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.3.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.3.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.3.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.3.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.3.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.4.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.4.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.4.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.4.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.4.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.4.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.4.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.4.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.4.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.4.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.4.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.4.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.5.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.5.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.5.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.5.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.5.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.5.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.5.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.5.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.5.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.5.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.5.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.5.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.6.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.6.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.6.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.6.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.6.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.6.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.6.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.6.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.6.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.6.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.6.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.6.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.7.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.7.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.7.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.7.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.7.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.7.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.7.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.7.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.7.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.7.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.7.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.7.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.8.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.8.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.8.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.8.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.8.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.8.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.8.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.8.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.8.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.8.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.8.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.8.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.9.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.9.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.9.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.9.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.9.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.9.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.9.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.9.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.9.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.9.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.9.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.9.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.10.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.10.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.10.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.10.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.10.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.10.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.10.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.10.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.10.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.10.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.10.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.10.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.11.pre_norm_mha.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.11.pre_norm_mha.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.11.pre_norm_mha.1.qkv_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.11.pre_norm_mha.1.qkv_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.11.pre_norm_mha.1.out_proj.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.11.pre_norm_mha.1.out_proj.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.11.pre_norm_ffn.0.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.11.pre_norm_ffn.0.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.11.pre_norm_ffn.1.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.11.pre_norm_ffn.1.bias from vision_ckpt\n",
      "Adding text_encoder.transformer.11.pre_norm_ffn.4.weight from vision_ckpt\n",
      "Adding text_encoder.transformer.11.pre_norm_ffn.4.bias from vision_ckpt\n",
      "Adding text_encoder.final_layer_norm.weight from vision_ckpt\n",
      "Adding text_encoder.final_layer_norm.bias from vision_ckpt\n",
      "Merge complete!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_pretrain = torch.load(\"/media/sdc/fe/ckpt_L14_ret/ckpt_best.pth\")\n",
    "vision_ckpt = torch.load(\"/media/sdc/fe/planB/InternVideo/InternVideo2/multi_modality/ckpts/mobileclip_vision.bin\")\n",
    "text_ckpt = torch.load(\"/media/sdc/fe/planB/InternVideo/InternVideo2/multi_modality/ckpts/mobileclip_blt.pt\")\n",
    "extra_ckpt = torch.load(\"/media/sdc/fe/planB/InternVideo/InternVideo2/multi_modality/ckpts/mobileclip_extra.bin\")\n",
    "\n",
    "pretrain_model_weight = ckpt_pretrain['model']\n",
    "\n",
    "for key, value in vision_ckpt.items():\n",
    "    if key not in pretrain_model_weight:\n",
    "        print(f\"Adding {key} from vision_ckpt\")\n",
    "        pretrain_model_weight[key] = value\n",
    "\n",
    "for key, value in text_ckpt.items():\n",
    "    if key not in pretrain_model_weight:\n",
    "        print(f\"Adding {key} from vision_ckpt\")\n",
    "        pretrain_model_weight[key] = value\n",
    "\n",
    "for key, value in extra_ckpt.items():\n",
    "    if key not in pretrain_model_weight:\n",
    "        print(f\"Adding {key} from vision_ckpt\")\n",
    "        pretrain_model_weight[key] = value\n",
    "\n",
    "torch.save(ckpt_pretrain, \"/media/sdc/fe/ckpt_L14_ret/merged_ckpt.pth\")\n",
    "print(\"Merge complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "val_path = \"/media/sdc/datasets/ssv2/validation_frames_label_options.json\"\n",
    "demo_path = \"/media/sdc/datasets/ssv2/validation_19demo.json\"\n",
    "\n",
    "with open(val_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    val_data = json.load(f)\n",
    "\n",
    "test_data = val_data[:19]\n",
    "json.dump(test_data, open(demo_path, \"w\", encoding=\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "model_2 = torch.load(\"/media/sdc/fe/ckpt_planb/ckpt_02.pth/mp_rank_00_model_states.pt\")\n",
    "model_1 = torch.load(\"/media/sdc/fe/InternVideo/InternVideo2/multi_modality/InternVideo2-Stage2_1B-224p-f4/InternVideo2-stage2_1b-224p-f4.pt\")\n",
    "\n",
    "print(model_1[\"module\"].keys())\n",
    "print(model_2[\"module\"].keys())\n",
    "\n",
    "for check_key in model_2.keys():\n",
    "    if not isinstance(model_2[])\n",
    "    extra_key_in_model_2 = set(model_2[check_key].keys()).difference(set(model_1[check_key].keys()))\n",
    "    print(f\"extra keys in model2{[check_key]}:{extra_key_in_model_2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "validation_path = \"/media/sdc/datasets/ssv2/annotations/validation.json\"\n",
    "candidates_id_path = \"/media/sdc/datasets/ssv2/annotations/labels.json\"\n",
    "candidates_pure_path = \"/media/sdc/datasets/ssv2/action_candidates.json\"\n",
    "save_path = \"/media/sdc/datasets/ssv2/validation_.json\"\n",
    "\n",
    "val_id_label = []\n",
    "\n",
    "with open(validation_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    val_data = json.load(f)\n",
    "    for item in val_data:\n",
    "        new_item = {}\n",
    "        new_item[\"id\"] = item[\"id\"] + \".webm\"\n",
    "        template = item[\"template\"].replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        with open(candidates_id_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            candidates_id_list = json.load(f)\n",
    "            new_label_id = candidates_id_list[template]\n",
    "            new_item[\"answer\"] = new_label_id\n",
    "        \n",
    "        with open(candidates_pure_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            candidates_list = json.load(f)\n",
    "            new_item[\"options\"] = candidates_list\n",
    "        \n",
    "        print(new_item)\n",
    "        val_id_label.append(new_item)\n",
    "\n",
    "json.dump(val_id_label, open(save_path, \"w\"), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并pth\n",
    "\n",
    "import torch\n",
    "\n",
    "main_model_path = \"/media/sdc/fe/InternVideo/InternVideo2/multi_modality/InternVideo2-Stage2_1B-224p-f4/InternVideo2-stage2_1b-224p-f4.pt\"\n",
    "model = torch.load(main_model_path)\n",
    "output_path = \"/media/sdc/fe/planB/InternVideo/InternVideo2/multi_modality/ckpts/complete_clip_1B.pth\"\n",
    "\n",
    "fine_tuned_attention_pool_path = \"/media/sdc/fe/ckpt_planb/ckpt_02.pth/mp_rank_00_model_states.pt\"\n",
    "fine_tuned_params = torch.load(fine_tuned_attention_pool_path)\n",
    "\n",
    "common_keys = set(model[\"module\"].keys()).intersection(set(fine_tuned_params[\"module\"].keys()))\n",
    "\n",
    "for key in fine_tuned_params[\"module\"]:\n",
    "    if key in common_keys:\n",
    "        print(f\"replace module {key} in ori path...\")\n",
    "        model[\"module\"][key] = fine_tuned_params[\"module\"][key]\n",
    "    else:\n",
    "        print(f\"add module {key} in ori path...\")\n",
    "        model[\"module\"][key] = fine_tuned_params[\"module\"][key]\n",
    "\n",
    "torch.save(model, output_path)\n",
    "\n",
    "print(f\"updated model saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build train_json\n",
    "import json\n",
    "\n",
    "ori_train_path = \"/media/sdc/datasets/ssv2/annotations/train.json\"\n",
    "candidates_id_path = \"/media/sdc/datasets/ssv2/annotations/labels.json\"\n",
    "candidates_pure_path = \"/media/sdc/datasets/ssv2/action_candidates.json\"\n",
    "train_save_path = \"/media/sdc/datasets/ssv2/train_sc.json\"\n",
    "\n",
    "train_update = []\n",
    "with open(ori_train_path, \"r\") as f:\n",
    "    ori_train_file = json.load(f)\n",
    "\n",
    "    for item in ori_train_file:\n",
    "        new_item = {}\n",
    "        new_item[\"id\"] = item[\"id\"] + \".webm\"\n",
    "        \n",
    "        with open(candidates_id_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                template = item[\"template\"].replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "                candidates_id_list = json.load(f)\n",
    "                new_label_id = candidates_id_list[template]\n",
    "                new_item[\"answer\"] = new_label_id\n",
    "\n",
    "        with open(candidates_pure_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                candidates_list = json.load(f)\n",
    "                new_item[\"options\"] = candidates_list\n",
    "\n",
    "        train_update.append(new_item)\n",
    "\n",
    "json.dump(train_update, open(train_save_path, \"w\"), ensure_ascii=False)\n",
    "\n",
    "\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build train_json_with_caption\n",
    "import json\n",
    "\n",
    "train_ori_path = \"/media/sdc/datasets/ssv2/annotations/train.json\"\n",
    "save_path = \"/media/sdc/datasets/ssv2/train_with_caption.json\"\n",
    "\n",
    "train_cap = []\n",
    "\n",
    "with open(train_ori_path, \"r\") as f:\n",
    "    train_ori_file = json.load(f)\n",
    "    \n",
    "    for item in train_ori_file:\n",
    "        new_item = {}\n",
    "        new_item[\"video\"] = item[\"id\"]\n",
    "        new_item[\"caption\"] = item[\"template\"].replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "        train_cap.append(new_item)\n",
    "    json.dump(train_cap, open(save_path, \"w\"), ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wash validation data\n",
    "import json\n",
    "import os\n",
    "\n",
    "val_with_id_path = \"/media/sdc/datasets/ssv2/validation_sc.json\"\n",
    "val_with_caption_path = \"/media/sdc/datasets/ssv2/validation_with_caption.json\"\n",
    "\n",
    "val_with_caption = []\n",
    "with open(val_with_id_path, \"r\") as f:\n",
    "    val_with_id = json.load(f)\n",
    "    for item in val_with_id:\n",
    "        item_with_caption = {}\n",
    "        item_with_caption[\"video\"] = os.path.splitext(item[\"id\"])[0]\n",
    "        item_with_caption[\"answer\"] = item[\"answer\"]\n",
    "        caption_idx = int(item[\"answer\"])\n",
    "        item_with_caption[\"caption\"] = item[\"options\"][caption_idx]\n",
    "        item_with_caption[\"options\"] = item[\"options\"]\n",
    "        val_with_caption.append(item_with_caption)\n",
    "    json.dump(val_with_caption, open(val_with_caption_path, \"w\"), ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wash validation data mc\n",
    "import json\n",
    "import os\n",
    "\n",
    "val_with_id_path = \"/media/sdc/datasets/ssv2/ssv2_mc_val.jsonl\"\n",
    "val_with_caption_path = \"/media/sdc/datasets/ssv2/validation_mc.json\"\n",
    "\n",
    "val_with_caption = []\n",
    "with open(val_with_id_path, \"r\") as f:\n",
    "    datalist = [json.loads(line) for line in f]\n",
    "    for item in datalist:\n",
    "        item_with_caption = {}\n",
    "        item_with_caption[\"video\"] = os.path.splitext(item[\"clip_name\"])[0]\n",
    "        item_with_caption[\"answer\"] = item[\"answer\"]\n",
    "        caption_idx = int(item[\"answer\"])\n",
    "        item_with_caption[\"caption\"] = item[\"options\"][caption_idx]\n",
    "        item_with_caption[\"options\"] = item[\"options\"]\n",
    "        val_with_caption.append(item_with_caption)\n",
    "    json.dump(val_with_caption, open(val_with_caption_path, \"w\"), ensure_ascii=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viclip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
